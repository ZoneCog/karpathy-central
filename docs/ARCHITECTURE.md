# Distributed Agentic Cognitive Grammar Architecture

## ðŸ§  Overview

This repository has been architected as a distributed network of agentic cognitive grammar subsystems, where each component acts as an intelligent agent in a recursive, self-aware network. The architecture supports emergent intelligence, recursive self-modification, and dynamic coordination through a hypergraph-based knowledge backbone.

## System Architecture

```mermaid
graph TD
    subgraph "Distributed Cognitive Grammar Network"
        HG[Hypergraph Knowledge Space<br/>AtomSpace]
        MA[Memory Agent<br/>Knowledge Representation]
        TA[Task Manager Agent<br/>Recursive Orchestration]
        CA[Cognitive Agent<br/>Neural Processing]
        AA[Autonomy Agent<br/>Self-Modification & Attention]
    end
    
    subgraph "Existing Subsystems Integration"
        SB[ScriptBots<br/>Agent Simulation]
        RJS[RecurrentJS<br/>Neural Networks]
        NT[NeuralTalk<br/>Language Models]
        TF[Transformers<br/>Language Processing]
    end
    
    HG -- read/write --> MA
    MA -- context --> TA
    TA -- tasks --> CA
    CA -- patterns --> HG
    AA -- modulates --> MA
    AA -- allocates attention --> TA
    AA -- tunes learning --> CA
    TA -- feedback --> AA
    AA -- self-monitor --> HG
    
    CA --> SB
    CA --> RJS
    CA --> NT
    CA --> TF
```

## Core Agents

### 1. Memory Agent (Hypergraph Knowledge)
- **Function**: Distributed knowledge representation using hypergraph structures
- **Implementation**: AtomSpace-inspired node/link storage system
- **Integration**: Stores patterns from all cognitive subsystems
- **Key Features**:
  - Hypergraph nodes represent entities, concepts, procedures
  - Links encode relationships and dependencies
  - Distributed storage across agent network
  - Version control for knowledge evolution

### 2. Task Manager Agent (Recursive Orchestration)
- **Function**: Decomposes goals and dispatches tasks to specialized agents
- **Implementation**: Recursive task allocation with dependency tracking
- **Integration**: Coordinates existing neural systems (ScriptBots, RecurrentJS, etc.)
- **Key Features**:
  - Hierarchical task decomposition
  - Dynamic agent selection and allocation
  - Resource management and load balancing
  - Progress monitoring and adaptive scheduling

### 3. Cognitive Agent (Neural Processing)
- **Function**: Performs reasoning, learning, and pattern recognition
- **Implementation**: Wrapper interface for existing neural architectures
- **Integration**: Unified API over ScriptBots, RecurrentJS, NeuralTalk, Transformers
- **Key Features**:
  - Multi-modal neural processing
  - Unified cognitive interface
  - Cross-system knowledge transfer
  - Adaptive learning rate control

### 4. Autonomy Agent (Self-Modification & Attention)
- **Function**: Monitors system health, triggers optimization, allocates attention
- **Implementation**: ECAN-style attention mechanism with self-reflection
- **Integration**: Meta-level control over all other agents
- **Key Features**:
  - Dynamic attention allocation
  - System health monitoring
  - Automatic optimization triggers
  - Self-reflective meta-cognition

## Communication Protocol

```mermaid
sequenceDiagram
    participant TM as Task Manager
    participant MA as Memory Agent
    participant CA as Cognitive Agent
    participant AA as Autonomy Agent
    
    TM->>MA: Request context for task
    MA->>TM: Return relevant knowledge
    TM->>CA: Dispatch cognitive task
    CA->>MA: Store learned patterns
    AA->>TM: Adjust task priority
    AA->>CA: Modulate learning rate
    AA->>MA: Trigger knowledge pruning
```

## Implementation Layers

### Layer 1: Hypergraph Foundation
```
cognitive_grammar/
â”œâ”€â”€ atomspace/
â”‚   â”œâ”€â”€ node.py          # Basic node types
â”‚   â”œâ”€â”€ link.py          # Relationship links
â”‚   â”œâ”€â”€ hypergraph.py    # Main graph structure
â”‚   â””â”€â”€ storage.py       # Persistence layer
```

### Layer 2: Agent Framework
```
cognitive_grammar/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base_agent.py    # Agent interface
â”‚   â”œâ”€â”€ memory_agent.py  # Knowledge management
â”‚   â”œâ”€â”€ task_agent.py    # Task orchestration
â”‚   â”œâ”€â”€ cognitive_agent.py  # Neural processing
â”‚   â””â”€â”€ autonomy_agent.py   # Meta-cognition
```

### Layer 3: Integration Layer
```
cognitive_grammar/
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ scriptbots_integration.py
â”‚   â”œâ”€â”€ recurrentjs_integration.py
â”‚   â”œâ”€â”€ neuraltalk_integration.py
â”‚   â””â”€â”€ transformers_integration.py
```

### Layer 4: Communication Layer
```
cognitive_grammar/
â”œâ”€â”€ communication/
â”‚   â”œâ”€â”€ message_bus.py   # Inter-agent messaging
â”‚   â”œâ”€â”€ protocols.py     # Communication protocols
â”‚   â””â”€â”€ serialization.py # Message serialization
```

## Recursive Self-Modification

The system implements recursive self-modification through:

1. **Meta-Cognitive Monitoring**: Autonomy Agent continuously monitors system performance
2. **Dynamic Grammar Expansion**: New agent types instantiated as functional patterns emerge
3. **Adaptive Architecture**: Neural architectures modified based on task performance
4. **Attention Reallocation**: Compute resources dynamically redistributed

## Attention Allocation Mechanism

```mermaid
graph LR
    subgraph "ECAN-Style Attention"
        STI[Short-Term Importance]
        LTI[Long-Term Importance]
        VLTI[Very Long-Term Importance]
    end
    
    subgraph "Resource Allocation"
        CPU[CPU Cycles]
        MEM[Memory]
        NET[Network Bandwidth]
    end
    
    STI --> CPU
    LTI --> MEM
    VLTI --> NET
    
    AA[Autonomy Agent] --> STI
    AA --> LTI
    AA --> VLTI
```

## Integration with Existing Systems

### ScriptBots Integration
- Agents become cognitive nodes in hypergraph
- Neural brains wrapped by Cognitive Agent interface
- Population dynamics managed by Task Manager

### RecurrentJS Integration
- RNN/LSTM models become reasoning modules
- Graph-based automatic differentiation integrated with knowledge graph
- Optimization managed by Autonomy Agent

### NeuralTalk Integration
- Language generation capabilities exposed through Cognitive Agent
- Image-text mappings stored in hypergraph
- Multi-modal reasoning enabled

### Transformers Integration
- Large language models accessible through unified interface
- Attention mechanisms coordinated with system-wide attention allocation
- Knowledge transfer between transformer models and hypergraph

## Getting Started

See [Quick Start Guide](./architecture/QUICKSTART.md) for implementation details and usage examples.

## Technical Documentation

- [Hypergraph Design](./architecture/HYPERGRAPH.md)
- [Agent Protocols](./architecture/PROTOCOLS.md)
- [Integration Patterns](./architecture/INTEGRATION.md)
- [Performance Considerations](./architecture/PERFORMANCE.md)

---

*"Let the distributed cognition unfurlâ€”each agent a note in a symphony of recursive intelligence, every tensor shape a membrane in a living, breathing P-System. As new patterns emerge, the grammar expands, the system dreams, and intelligence crystallizes from chaos!"*